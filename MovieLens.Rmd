---
title: "MovieLens Recommendation System Project"
subtitle : "HarvardX's Data Science Professional Certificate" 
author: "Otman Cherrati"
date: "July 16, 2021"
output: 
  pdf_document: 
    toc: yes
    number_sections: yes
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'left', cache=FALSE,
                      cache.lazy = FALSE)
```

\newpage


# Intorduction :

  This report is part of the final capstone course of HarvardX Data Science Professional certificate taught by the famous professor Rafael Irizzary. 
The report is on MovieLens data set. MovieLens is run by GroupLens Research, a research lab in the Department of Computer Science and Engineering at the University of Minnesota. 
MovieLens recommends movies for its users to watch, based on their film preferences using collaborative filtering of members movie ratings and movie reviews.

## Object :
   Our goal in this analysis is to create a movie recommendation system, using
   MovieLens 10M data set, the system must be capable of generate predictions    of users rating based on a training datavset.
   
  We will start by taking a look on the databset and then exploring the different    variables to see if there is any trends that can help us make some assumptions.
  After cleaning the data we will start building and testing our models based on what we have learned in the exploratory analysis. 
  The evaluation of the models is based on the RMSE - Root Mean Squared Error that should be at least lower than 0.87750.
  $$\mbox{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_{i} - \hat{y_{i}})^2}$$
  Finally we will apply our final best model to the validation data set and discuss the results.

\vspace{0.5cm}
  
## package used :

  **tidyverse** \
  **dplyr** \
  **ggplot2** \
  **stringr** \
  **data.table** \
  **caret** \
  **lubridate** \
  **Xgboost** \
  **knitr**\
  
```{r, include=FALSE, echo=FALSE}
# Install all needed libraries if it is not present
if(!require(tidyverse)) install.packages("tidyverse") 
if(!require(tidyr)) install.packages("tidyr")
if(!require(stringr)) install.packages("stringr")
if(!require(ggplot2)) install.packages("ggplot2")
if(!require(data.table)) install.packages("data.table")
if(!require(lubridate)) install.packages("lubridate")
if(!require(xgboost)) install.packages("Xgboost")
if(!require(knitr)) install.packages("knitr")
```

```{r, include=FALSE, echo=FALSE}
# load libraries
library(tidyverse)
library(stringr)
library(ggplot2)
library(tidyr)
library(data.table)
library(lubridate)
library(xgboost)
library(knitr)
memory.limit(size = 12288) # for windows users(in the case the limit is limited in 8Gb)

options(digits = 5)

#NB : You may have to close other windows and run "rm(list = ls)" to make the code run smoothly, the whole code may take a while.
```

\vspace{1cm}
## Session-Information :
The output of sessionInfo() is placed here for reproducibility purposes.
```{r, echo=FALSE}
sessionInfo()
```


\vspace{1cm}
## Load the movilens data set :
 To load the data set we run the code provided by Edx.
```{r, include=FALSE, echo=FALSE}
##########################################################
# Create edx set, validation set (final hold-out test set)
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse",
                                         repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret",
                                     repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table",
                                          repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)
library(lubridate)



# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t",
                             readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(
  unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")


# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))


movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use set.seed(1)
test_index <- createDataPartition(y = movielens$rating, times = 1,
                                  p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

# Save validation data and remove it from environment  for now :

fwrite(validation, "validation.csv")

rm(dl, ratings, movies, test_index, temp, movielens, removed,
   validation)
gc()

```


## Dataset Description

We will use the 10M version of the MovieLens dataset. The 10 Millions dataset has been divided into two dataset: edx for training purpose and validation for the final validation phase.

The edx dataset contains approximately 9 Millions of rows, where every row represent a rating, with 69878 different users and 10677 movies.

We will focus in our exploration and analysis on Edx data set, the validation set has the same variables and will only be used in the final step.

\newpage
# Data Exploration :

## Initial exploration :

**The structure** :\
From the str() function we see the dimension, the names and class of the variables. 
\vspace{1cm}
```{r , echo=FALSE}
str(edx)
```
\vspace{1cm}

The six features of the data set are (same as validation) : \
**movieId:** Unique ID for the movie. \
**userId:** Unique ID for the user. \
**rating:** A rating between 0 and 5 for the movie. \
**timestamp:** Date and time the rating was given. \
**title:** Movie title and Year the movie was released. (not unique). \
**genres:** Genres associated with the movie. \

\vspace{1cm}
Let's take a look on the first six rows of Edx data :

```{r , echo=FALSE}
head(edx) %>% kable()
```

The Edx data contains 9000055 rows and 6 variables
```{r , echo=FALSE}
dim(edx) %>%  t() %>% kable(caption = "Number of rows and columns", col.names = c("rows", "columns"))
```

\newpage
**Look for missing values** : \
we notice that there is no missing values  in the edx dataset.
```{r, echo=FALSE}
sapply(edx, function(i){
  sum(is.na(i))
}) %>% kable(col.names = c("Number of NAs"))
```

\vspace{1cm}
**Number of movies and users** :

```{r, echo=FALSE}
edx %>%
  summarize("Number of unique users" = n_distinct(userId),
                 "Number of unique movies" = n_distinct(movieId)) %>%
  knitr::kable()
```

\newpage
## Variables Exploration

### Movies :


```{r echo=FALSE, fig.height=4}
edx %>% 
  count(movieId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() + theme_bw() +
  ggtitle("Movies distribution") + theme_bw() +
  xlab("number of ratings")
```

We notice from the 10677 different movies in the edx set, some movies  are rated more than the others, movies don't have the same popularity. \
\vspace{1cm}

**First six most rated movies**
```{r echo=FALSE, message=FALSE, warning=FALSE}
edx %>% group_by(movieId, title) %>% summarise(n = n()) %>%
        arrange(desc(n)) %>% head() %>% kable(col.names = c("MovieID", "Title", "Number of ratings"))
```


We notice that 90% of movies are rated at least 10 times:
```{r, echo=FALSE}
edx %>% dplyr::count(movieId) %>%
        summarise("movies which are rated at least 10 times" = mean(n>=10)) %>% knitr::kable()
```

**Summary of rating per movies:**  \
The average number of rating per movie is  about 843.
```{r, echo=FALSE}
edx %>% group_by(movieId) %>% 
        summarise(number_of_ratings = n()) %>% 
        ungroup() %>% pull(number_of_ratings) %>%
        summary() %>% t() %>% kable()
```


### users


```{r echo=FALSE, fig.height=4, warning=FALSE}
edx %>%
  dplyr::count(userId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() + theme_bw() +
  ggtitle("User distribution") +
  xlab("number of ratings") 
```

We notice that the user distribution is right skewed.
Not every user is equally active. Some users have rated very few movie and others have rated a lot of movies.
\vspace{1cm}

**Six users that rated the most :**
```{r, echo=FALSE}
edx %>% dplyr::count(userId) %>% 
        arrange(desc(n)) %>% head() %>% 
        kable(col.names = c("UserID", "Number of rating"))
```


**Summary rating per users:** \
The average number rating per user is about 128 ratings

```{r, echo=FALSE}
edx %>% group_by(userId) %>% 
        summarise(number_of_ratings = n()) %>%  ungroup() %>%
        pull(number_of_ratings) %>%
        summary() %>% t() %>% kable()
```

95 % of the users rated more than 20 movies

```{r, echo=FALSE}
edx %>% dplyr::count(userId) %>% 
        summarise("users who rated more than 20 movies" = mean(n>=20)) %>% 
  knitr::kable()
```


### Rating 


**Total number for each rating:**
```{r, echo=FALSE}
edx %>% dplyr::count(rating) %>% 
        arrange(desc(n)) %>% 
        kable(col.names = c("Rating", "Total number"))
```

From the 9000055 ratings in the edx data the rating range is between 0.5 and 5 with 10 possible choices.

```{r echo=FALSE, fig.height=4}
edx %>% ggplot(aes(rating)) + 
        geom_bar() + theme_bw() +
        ggtitle("Distribution of rating")
```
We notice that some rating values are given more than the others, that most ratings get rounded value and that users have a general tendency to rate movies between 3 and 4. \

\newpage
**Average rating per user :**
```{r echo=FALSE, fig.height=4, message=FALSE, warning=FALSE}
edx %>% group_by(userId) %>% 
        summarise(avg_rating = mean(rating)) %>%
        ggplot(aes(avg_rating)) + 
        geom_histogram(color = "black") +
        theme_bw() +
        ggtitle("Average rating per user")
```
The distribution  is almost symmetric with outliers to the left, users  give on average rating of 3.6 in a range from 0.5 to 5. The variation of average rating from user to user make it very important to include user effect in any farther analysis.

\vspace{1cm}

 Summary of average rating per user :
```{r, echo=FALSE}
edx %>% group_by(userId) %>% 
        summarise(avg_rating = mean(rating)) %>%
        pull(avg_rating) %>% summary() %>% t() %>% kable()
```

93% of users have an average rating of at least 3
```{r, echo=FALSE}
edx %>% group_by(userId) %>% 
              summarise(avg_rating = mean(rating)) %>% 
              summarise(mean(avg_rating >= 3)) %>% 
              knitr::kable(col.names = "Users who give at least a 3 star")
```


\newpage
 **Average rating per movie:**
```{r echo=FALSE, fig.height=4, message=FALSE, warning=FALSE}
edx %>% group_by(movieId) %>% 
        summarise(avg_rating = mean(rating)) %>%
        ggplot(aes(avg_rating)) + 
        geom_histogram(color = "black") + theme_bw()
```
The distribution skewed to the left, this means that most movies get rating more than the average of average rating per movie. This pattern will certainly have an effect on rating predictions.
\vspace{1cm}

 Summary of average rating per movie
```{r, echo=FALSE}
edx %>% group_by(movieId) %>% 
        summarise(avg_rating = mean(rating)) %>%
        pull(avg_rating) %>% summary() %>% 
        t() %>% kable()
```


67% of movies have an average rating more than 3 stars :
```{r, echo=FALSE}
edx %>% group_by(movieId) %>% 
              summarise(avg_rating = mean(rating)) %>% 
     summarise(mean(avg_rating > 3)) %>% 
     knitr::kable(col.names = "Movie with average rating more than 3")
```

\vspace{1cm}
### Date :

We will have to do some data processing to explore the date of release and date of rating.

#### Date of rating : \
**Convert timestamp to year of rating** 

```{r, include=FALSE, echo=FALSE}
edx <- edx %>% mutate(
  rating_year = as.integer(
        year(date(as_datetime(timestamp, origin = "1970-01-01"))))) %>% 
  select(-timestamp)
```

 That's how the data looks like now :

```{r, echo=FALSE}
head(edx) %>% knitr::kable()
```

 **Summary of year of rating : **

The rating starts in 1995, ends in 2009 and last more than 14 years.

```{r, echo=FALSE}
range <- range(edx$rating_year)

diff <- diff(range(edx$rating_year))

data.frame("Start" = range[1], "End" = range[2], "Period" = diff) %>% knitr::kable()

rm(diff, range) 
```



**The ten years with most number of ratings:**
```{r, echo=FALSE}
edx %>% group_by(rating_year) %>% 
        summarise(n=n()) %>% 
        head(10) %>% 
        kable(col.names = c("year of rating", "number of ratings"))
```
 



```{r echo=FALSE, fig.height=4}
edx %>% ggplot(aes(rating_year)) + 
        geom_histogram(binwidth = 1, color = "black") + theme_bw() +
        ggtitle("Distribution of number of ratings  per year of rating")
```
We can see that the number of ratings per year has increased since 1995, has reached a maximum of 1144349 in 2002 and since then it has been around 60000. This means that the way the users rate movies has evolved over the time. The time of rating could also have an effect on the rating a movie will get.

\vspace{1cm}


#### Year of release: \
 
```{r, include=FALSE, echo=FALSE}
edx <- edx %>% mutate(title = str_trim(title)) %>% 
  extract(title, c("title_1", "release"),
          regex = "^(.*) \\(([0-9 \\-]*)\\)$",
          remove = F) %>% 
  mutate(release = if_else(str_length(release) > 4,
                           as.integer(str_split(release, "-",
                                                simplify = T)[1]),
                           as.integer(release))) %>% 
  mutate(title = if_else(is.na(title_1), title,
                         title_1)) %>% select(-title_1)
```

We'll extract the year of release from the title and take a look on the data : 

```{r, echo=FALSE}
head(edx) %>% knitr::kable()
```

 **Summary year of relaese:**

```{r,include=FALSE, echo=FALSE}
range <- range(edx$release)
diff <- diff(range)
```

The first movie was released in 1915 and the last one 2008.
```{r, echo=FALSE}
data.frame("Start" = range[1], "End" = range[2], "period" = diff) %>% 
  knitr::kable()
rm(diff, range)
```



```{r echo=FALSE, fig.height=4}
edx %>% group_by(release) %>% 
        summarise(n = n()) %>%
        ggplot(aes(release, n)) + 
        geom_line(color = "red") + theme_bw() + 
        ggtitle("Distribution of ratings per year of release") + 
        ylab("number of ratings")
```
The number of ratings has increased since the start of the movie making, it has reached its pic around 1995, but it has dropped since then. The number of rating of a movie depends also on the year it was released, this may affect the chance of a movie of having good ratings.


**The 10 years of release with the most rated movies:**
```{r, echo=FALSE}
edx %>% group_by(release) %>%  
        summarise(n=n()) %>% arrange(desc(n)) %>%
        head(10) %>% kable(col.names = c("year if release" ,"number of rating"))
```


 
\vspace{1cm}
```{r echo=FALSE, fig.height=4}
edx %>% filter(!duplicated(movieId)) %>% 
        dplyr::count(release) %>%
        ggplot(aes(release, n)) +
        geom_line(color = "blue") + theme_bw() +
        ggtitle("distribution of released movies per year") +
        ylab("number of movies released")
```
The number of movies released has increased since 1915 and it has reached the max in on 2002. This is obvious since the movie making has evolved over time.
\vspace{1cm}

 **Number of released movies per year**
 
 The 10 years with most released movies :
```{r, echo=FALSE}
edx %>% filter(!duplicated(movieId)) %>% dplyr::count(release) %>%
  arrange(desc(n)) %>% head(10) %>% knitr::kable()
```


\newpage
### Genre
Genres with most number of ratings (genre in attached format) :
```{r, echo=FALSE}
edx %>% dplyr::count(genres) %>%
        arrange(desc(n)) %>% head() %>% 
  kable(col.names = c("genres", "number of ratings"))
```

Number of genres combinations (genres attached) :
```{r, echo=FALSE}
unique(edx$genres) %>% length() %>%
  kable(col.names = "Number of genres")
```

We will split the genres so as to have one genre in each row.
```{r, echo=FALSE, include=FALSE}
edx <- edx %>% separate_rows(genres, sep = "\\|")
gc()
```

This is how the data looks now:
```{r, echo=FALSE}
head(edx) %>% knitr::kable()
```

**Number of unique genres in our data :** 
```{r, echo=FALSE}
cat("The number of genres is", unique(edx$genres) %>% length())
```

\vspace{1cm}
**Number of ratings per each genre :**
```{r, echo=FALSE}
edx %>% dplyr::count(genres) %>% 
        arrange(desc(n)) %>% 
        kable(col.names = c("genres", "number of ratings"))
```

We notice that the "no listed genre" is present just 8 times, compared to the other genrs it's almost insignificant,  we can either assign it to the the most present genres (Drama and Comedy) or just remove it. We will remove it.
```{r, echo=FALSE}
edx <- edx %>% filter(genres != "(no genres listed)")
```

\vspace{1cm}

```{r, echo=FALSE}
edx %>% mutate(genres = factor(genres,
          levels = names(sort(table(edx$genres), decreasing = TRUE)))) %>%
        ggplot(aes(genres)) +  geom_bar(fill = "blue") + theme_bw() +
        theme(axis.text.x = element_text(angle = 90)) +
        ggtitle("barplot of the number ratings per genres")
```

We notice that some genres get rated much more than the others, maybe it's because some genres are more popular than others.  Including the genre in the analysis may give batter results.

\newpage
# Data preprocessing :

```{r, echo=FALSE, include=FALSE}
library(caret)
```

  
## Data cleaning :

We will remove the title variable since it won't help us in our analysis.
```{r echo=FALSE}
edx <- edx %>% 
       select(-title) # we don't need it anymore
```

  The data is already cleaned, so now we will only encode genres to binary to make it suitable for some type of models.
```{r, echo=FALSE}
edx <- edx %>% mutate(value = rep(1, nrow(edx))) %>%
  spread(key = genres, value = value, fill = 0) %>% as.data.frame()
```

## Create train and test set :
 The train set will be 80% of the edx data while the test set will be 20%.
```{r, echo=FALSE, include=FALSE}
set.seed(1, sample.kind = "Rounding")

test_index <- createDataPartition(edx$rating, times = 1, p = 0.2, list = FALSE)

train <- edx %>% dplyr::slice(-test_index)
temp <- edx %>% dplyr::slice(test_index)
test <- temp %>% semi_join(train, by = "movieId") %>% 
  semi_join(train, by = "userId")
removed <- anti_join(temp, test)
train <- rbind(train, removed)
rm(temp, test_index, removed, edx)
gc()
```

\vspace{1cm}
**First six rows and a subset of columns from the train set** 
```{r, echo=FALSE}
head(train[1:6, c(1, 2, 3, 8, 15, 24)]) %>% knitr::kable()
```

\vspace{1cm}
**First six rows and a subset of columns from the train set** 
```{r, echo=FALSE}
head(test[1:6, c(1, 2, 3, 8, 15, 24)]) %>% knitr::kable()
```


\newpage
#   Models building :

\vspace{1cm}
  Machine learning algorithms in recommender systems typically fit into two categories: content-based systems and collaborative filtering systems. Modern recommender systems combine both approaches.

A) 
  Content-based methods are based on the similarity of movie attributes. Using this type of recommender system, if a user watches one movie, similar movies are recommended.  

B) 
  With collaborative filtering, the system is based on past interactions between users and movies. With this in mind, the input for a collaborative filtering system is made up of past data of user interactions with the movies they watch.

\vspace{1cm}
 In this project we will try some models starting with a naive approach based on the average rating, a 'content based' one based on the average movie, and start then using some collaborative methods. 
We will get the RMSE of the models on the test set.  The one with the least RMSE will then be applied on the validation set to get the final RMSE result.\
\vspace{1cm}

## Naive model : just the mean
In this simple model we will make our predictions, by simply using the mean of all ratings as the estimate for every unknown rating.
 

The formula used for this model is : 
$$Y_{u,i} = \hat{\mu} + \epsilon_{u,i}$$
with û the mean rating and upsilon a random error.

```{r, echo=FALSE}
mean_rating <- mean(train$rating)
cat(c("The mean rating in the train set is", mean_rating))
```

\vspace{1cm}

```{r, echo=FALSE}

just_avg <- RMSE(test$rating, mean_rating)
results <- data.frame("method" = "just the avg", "rmse" = just_avg)
results %>% kable(caption = "Results")
```

The rmse is 1.06 which is very big and that means that in average we are missing the true prediction by a whole star rating.

\vspace{1cm}

## Movie effect model :
Some movies are rated more often than others. So in this model we will take into account the variability from movie to movie. A bias term b_i will be calculated for each movie to determine how much better or worse a given film is from the overall average.
$$Y_{u,i} = \hat{\mu} + b_i + \epsilon_{u,i}$$

```{r, echo=FALSE, include=FALSE}
movies_avgs <- train %>%
               group_by(movieId) %>%
               summarize(movie_eff = mean(rating - mean_rating))

movie_eff <- test %>% 
             left_join(movies_avgs, by = "movieId") %>% 
             mutate(pred = mean_rating + movie_eff)

gc()
```

\vspace{1cm}

```{r, echo=FALSE}
movie_eff_rmse <- RMSE(test$rating, movie_eff$pred)

results <- results %>%  add_row(method = "movie_eff", rmse = movie_eff_rmse)

results %>% kable(caption = "Results")

rm(movie_eff)
```

Using the movie effect the RMSE on the test set is better but still not good enough.

\vspace{1cm}

## Movie plus User effect model :

Some users are positive and some have negative reviews because of their own personal liking/disliking regardless of movie.
Users may have a tendency to rate movies higher or lower than the overall mean. So let's add this into the model. First we'll calculate the bias for each user.
Then we'll combine the user bias  with the movie bias to get the prediction.
$$Y_{u,i} = \hat{\mu} + b_i + b_u + \epsilon_{u,i}$$

```{r, echo=FALSE, include=FALSE}
gc()
users_avgs <- train %>%
                    left_join(movies_avgs, by='movieId') %>%
                    group_by(userId) %>%
                    summarize(user_eff = mean(rating - mean_rating - movie_eff))

movie_user_eff <- test %>% 
                        left_join(movies_avgs, by = 'movieId') %>%
                        left_join(users_avgs , by = 'userId') %>% 
                        mutate(pred = mean_rating + movie_eff + user_eff) 

```


```{r, echo=FALSE}

movie_user_rmse <- RMSE(test$rating ,  movie_user_eff$pred)
results <- results %>% 
                    add_row(method = "movie_user_eff", rmse = movie_user_rmse)

results %>% kable(caption = "Results")

rm(movie_user_eff)
```
With the movie_user combination the results are good, the rmse tells us that we are making good predictions, but can we do even better.

\vspace{1cm}

## Movie, User and release year effect model :
The popularity of the movie genre depends strongly on the contemporary issues. So we should also add the release date bias b_l to our analysis.
$$Y_{u,i} = \hat{\mu} + b_i + b_u + b_l + \epsilon_{u,i}$$

```{r, echo=FALSE, include=FALSE}
gc()

release_avgs <- train %>%
    left_join(movies_avgs, by='movieId') %>% 
    left_join(users_avgs, by="userId") %>%
    group_by(release) %>%
    summarize(release_eff = 
              mean(rating - mean_rating - movie_eff - user_eff ))
release_eff <- test %>% 
    left_join(movies_avgs, by = 'movieId') %>%
    left_join(users_avgs , by = 'userId') %>%
    left_join(release_avgs, by="release") %>%
    mutate(pred = mean_rating + movie_eff + user_eff + release_eff)

```

\vspace{1cm}

```{r, echo=FALSE}
movie_user_release_rmse <- RMSE(test$rating ,  release_eff$pred)

results <- results %>% 
    add_row(method = "movie_user_rel_eff", rmse = movie_user_release_rmse)

results %>% kable(caption = "Results")

rm(release_eff)
```

The RMSE didn't change that much, let's add the year of rating effect.

\vspace{1cm}

## Movie, User, release and rating year effect model :

The users mindset also has evolved over time. This can also effect the average rating of movies over the years. So we will add a rating date bias b_r to our model.
$$Y_{u,i} = \hat{\mu} + b_i + b_u + b_l + b_r + \epsilon_{u,i}$$
```{r, echo=FALSE, include=FALSE}
gc()

rat_year_avgs <- train %>%
   left_join(movies_avgs, by='movieId') %>% 
   left_join(users_avgs, by="userId") %>%
   left_join(release_avgs, by="release") %>%
   group_by(rating_year) %>%
   summarize(rat_year_eff = 
              mean(rating - mean_rating - movie_eff - user_eff - release_eff))
rat_year_eff <- test %>% 
   left_join(movies_avgs, by = 'movieId') %>%
   left_join(users_avgs , by = 'userId') %>% 
   left_join(release_avgs, by="release") %>%
   left_join(rat_year_avgs, by="rating_year") %>% 
   mutate(pred = 
    mean_rating + movie_eff + user_eff + release_eff + rat_year_eff)

```


```{r, echo=FALSE}
movie_user_year_rmse <- RMSE(test$rating ,  rat_year_eff$pred)

results <- results %>% 
           add_row(method = "movie_user_year_eff", rmse = movie_user_year_rmse)

results %>% kable(caption = "Results")

rm(rat_year_eff, movies_avgs, rat_year_avgs,release_avgs, users_avgs)
```

We can see that using the average rating per year don't affect much the rmse.
\vspace{1cm}


## Xgboost model : Extreme Gradient Boosting


 XGBoost stands for “Extreme Gradient Boosting,it is an extension to gradient boosted decision trees (GBM) and specially designed to improve speed and performance. 

  XGBoost, Like other gradient boosting algorithms, operates on decision trees, models that construct a graph that examines the input under various "if" statements. Whether the "if" condition is satisfied influences the next "if" condition and eventual prediction. XGBoost  progressively adds more and more "if" conditions to the decision tree to build a stronger model. 
XGBoost also works in a similar manner as Gradient Boosting model but introduces regularization terms to counter over_fitting..   

### Xgboost data processing :

From the last model we conclude that there is an impact of the  movie effect and user effect  on the rating, normally we would have encoded the user ID and movie ID to binaries, but this would have resulted in a very large data with thousands of columns since the number of movies and users is very large, so we won't be using movie and user ID in the model, but keep their effect we will add the averages of movies and users to their respective data sets (train and test) before deleting the ID's colums  to let our model take advantage of these features.

**Add averages to train set**

```{r, echo=FALSE, include=FALSE}
movies_avgs <- train %>% group_by(movieId) %>%
  summarise(mov_avg = mean(rating))

users_avgs <- train %>% group_by(userId) %>%
  summarise(user_avg = mean(rating))


train <- train %>% left_join(movies_avgs) %>% 
                   left_join(users_avgs) %>% 
                   as.data.frame()

rm(users_avgs, movies_avgs)
gc()
```

The data will look like this (subset of the train set) : (The IDs will be dropped in the next step)
```{r, echo=FALSE}
head(train[1:6, c(1, 2, 3, 8, 15, 24, 25, 26)]) %>% knitr::kable()
```

**Add averages to test set**

```{r, echo=FALSE, include=FALSE}

movies_avgs <- test %>% group_by(movieId) %>%
  summarise(mov_avg = mean(rating))

users_avgs <- test %>% group_by(userId) %>%
  summarise(user_avg = mean(rating))

test <- test %>% left_join(movies_avgs) %>% 
                 left_join(users_avgs) %>% 
                  as.data.frame()
rm(users_avgs, movies_avgs)
gc()
```
The data will look like this (subset of the test set) : (The IDs will be dropped in the next step)
```{r, echo=FALSE}
head(test[1:6, c(1, 2, 3, 8, 15, 24, 25, 26)]) %>% knitr::kable()
```


### Define predictor and response variables in the datasets :

We remove non necessary features(ids), convert our train and test set predictors to an object data.matrix and we define the target variables using this piece of code :
 
>train_x = data.matrix(train[, -c(1, 2, 3)]) \
>train_y = train[,3] \
>test_x = data.matrix(test[, -c(1, 2, 3)]) \
>test_y = test[, 3]\

```{r, echo=FALSE, include=FALSE}
gc()
train_x = data.matrix(train[, -c(1, 2, 3)])
train_y = train[,3]
rm(train)
test_x = data.matrix(test[, -c(1, 2, 3)])
test_y = test[, 3]
rm(test)
gc()
```

 


### define final training and testing sets :

xgb_train = xgb.DMatrix(data = train_x, label = train_y) \
xgb_test = xgb.DMatrix(data = test_x, label = test_y)

```{r, echo=FALSE, include=FALSE}
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
gc()
```


### Define watchlist :

watchlist = list(train=xgb_train, test=xgb_test)

```{r, echo=FALSE}
watchlist = list(train=xgb_train, test=xgb_test)
```


### Fit XGBoost model and display training and testing data at each round to chose the best parameters :

```{r echo=FALSE, message=FALSE, warning=FALSE}

set.seed(1, sample.kind = "Rounding")
model = xgb.train(data = xgb_train, max.depth = 10,
                  watchlist=watchlist, nrounds = 20)
```
                  
  
### Define final model :
Using the optimal parameters from the Xgb model we define the final model.
                
```{r, echo=FALSE}
final = xgboost(data = xgb_train, max.depth = 10, nrounds = 16, verbose = FALSE)
```

### Get predictions on test set :


```{r, echo=FALSE, include=FALSE}
gc()

y_pred <- predict(final, data.matrix(test_x))

rmse_xgboost <- RMSE(test_y, y_pred)

results <- results %>% add_row(method = "xgboost", rmse = rmse_xgboost)

rm(test_x, test_y, y_pred)
gc() 
```

```{r, echo=FALSE}
results %>% kable(caption = "Results")
```
The rmse of the Xgboost is the best among all the models we have tried, so we will aplly it to the validation set.

# Final results :

**Apply the winning model for on validation set**

  Based on the results we have got in the previous section, we know that the Xgboost model did the best. In this final section we will apply it on the validation data set and get the final RMSE. 
Before this we will have to do some data pre_processing on the the validation data set to have it on the same structure as the training set. \

## Validation loading and cleaning : \

\vspace{1cm}

 There is no missing values in the validation data set.
```{r, echo=FALSE}
validation <- fread("validation.csv") 

sapply(validation, function(i){
    sum(is.na(i))
}) %>% 
  kable(col.names = c("Number of NAs"))
```


We will extract the rating year, year of release and encode genres to binary in the validation data set. Then we will add the averages of rating per users and movies and remove the non needed columns.

```{r, echo=FALSE, include=FALSE}
gc()

validation <- validation %>% mutate(
    rating_year = as.integer(year(date(
                   as_datetime(timestamp, origin = "1970-01-01"))))) %>% 
                            select(-timestamp)

validation <- validation %>% mutate(title = str_trim(title)) %>% 
  extract(title, c("title_1", "release"),
          regex = "^(.*) \\(([0-9 \\-]*)\\)$",
          remove = F) %>% 
  mutate(release = if_else(str_length(release) > 4,
                           as.integer(str_split(release, "-",
                                                simplify = T)[1]),
                           as.integer(release))) %>% 
  mutate(title = if_else(is.na(title_1), title,
                         title_1)) %>% select(-title_1, -title)

validation <- validation %>% separate_rows(genres, sep = "\\|")

validation <- validation %>% mutate(value = rep(1, nrow(validation))) %>%
  spread(key = genres, value = value, fill = 0) %>% as.data.frame()


movies_avgs <- validation %>% group_by(movieId) %>%
  summarise(mov_avg = mean(rating))

users_avgs <- validation %>% group_by(userId) %>%
  summarise(user_avg = mean(rating))

validation <- validation %>% left_join(movies_avgs) %>% 
                             left_join(users_avgs) 

rm(users_avgs, movies_avgs)
gc()
```

**This a subset of the validation set**
```{r, echo=FALSE}
head(validation[1:6, c(1, 2, 3, 8, 15, 24, 25, 26)]) %>% knitr::kable()
```

\vspace{1cm}
## Validation set preparation :
In this step we define the matrix of predictors and the target variable.

```{r, echo=FALSE}
valid_x = data.matrix(validation[, -c(1, 2, 3)])
valid_y = validation[, 3]
```

\vspace{1cm}
## Run final model on validation set :
We run the final Xgboost model on the validation matrix.

```{r, echo=FALSE}

rat_pred <- predict(final, data.matrix(valid_x))
rmse_xgb_valid <- RMSE(valid_y, rat_pred)
cat(c("The RMSE of Xgboost applied on validation set is", rmse_xgb_valid))
```



  The overall objective to training a machine learning algorithm of course resides in being able to generate predictions. The models used in this project have given different results with the Xgboost being the best but requiring more resources. The method based on the averages is the most light and doesn't consume much resources.
After all the final model managed to perform a good result on the validation set.

\newpage
# Conclusion :
\vspace{1.5cm}
   The project goal was to build a model that predict movie ratings. Our approach undertaken here relied on an initial exploratory analysis with data visualizations, then we start building models based on the assumptions made in the last part. Finally, we chose the model that performs the least RMSE and applied it on the validation set which produced an RMSE of 0.84 that is better than out target of 0.864. 

   While these results are promising, future work could improve both predictive performance and speed of the algorithm in the following ways :\
  -Use smooth function to model the date effect.\
  - Use matrix factorization.\
  - Use models that consume less time and memory.\
  - Use sampling techniques as it permit to work on large data set while guaranteeing generalizability.